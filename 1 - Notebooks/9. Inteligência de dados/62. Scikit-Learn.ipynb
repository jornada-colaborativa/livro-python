{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega arquivo csv usando Pandas usando uma URL\n",
    "# Informa a URL de importação do dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "\n",
    "# Informa o cabeçalho das colunas\n",
    "colunas = [\n",
    "    'preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# Lê o arquivo utilizando as colunas informadas\n",
    "dataset = pd.read_csv(url, names=colunas, skiprows=0, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # dimensões do dataset\n",
    ">>> print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # tipos de cada atributo\n",
    ">>> print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # primeiras linhas do dataset\n",
    ">>> print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação em conjuntos de treino e teste\n",
    "array = dataset.values\n",
    "X = array[:, 0:8].astype(float)\n",
    "Y = array[:, 8]\n",
    "test_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "num_folds = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos modelos\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='newton-cg')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # definindo uma semente global\n",
    "\n",
    "# Avaliação dos modelos\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(\n",
    "        model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação dos modelos\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparação dos Modelos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # definindo uma semente global\n",
    "\n",
    "# Padronização do dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('LR', LogisticRegression(solver='newton-cg'))])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('NB', GaussianNB())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('SVM', SVC())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(\n",
    "        model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # definindo uma semente global\n",
    "\n",
    "# Tuning do KNN\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "\n",
    "k = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "distancias = [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "param_grid = dict(n_neighbors=k, metric=distancias)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Melhor: %f usando %s\" % \n",
    "    (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f): %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # definindo uma semente global\n",
    "\n",
    "# Tuning do SVM\n",
    "\n",
    "c_values = [0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Melhor: %f com %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f): %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # definindo uma semente global\n",
    "\n",
    "# Preparação do modelo\n",
    "model = LogisticRegression(solver='newton-cg')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Estimativa da acurácia no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy score = \", accuracy_score(Y_test, predictions))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "labels = [\"Sem diabetes\", \"Com diabetes\"]\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "cmd.plot(values_format=\"d\")\n",
    "plt.show()\n",
    "print(classification_report(Y_test, predictions, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
